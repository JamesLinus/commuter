#!/usr/bin/python

# XXX Linux and sv6 databases are mostly redundant.  Maybe have a
# "template" database that gives test information in order and then
# give results in equivalent order?

import sys
import argparse
import json
import itertools
import collections

def reformat_tests(testcases, add):
    """Convert testcases into format expected by viewer."""

    for testcase in testcases:
        # Split name
        suite, name = testcase.pop('name').split('-', 1)
        calls, pathid, testno = name.rsplit('_', 2)
        testno = int(testno)
        testcase['calls'] = calls
        testcase['pathid'] = pathid
        testcase['testno'] = testno

        # Remove redundant fields
        for shared in testcase['shared']:
            if any(f in shared for f in ['stack', 'stack1', 'stack2']):
                for pc in ['pc', 'pc1', 'pc2']:
                    if pc in shared:
                        del shared[pc]
            del shared['rawaddr']

        # Add identifying fields
        testcase.update(add)

    return testcases

def dedup_stacks(testcases):
    stacks = {}
    rstacks = {}
    for testcase in testcases:
        for shared in testcase['shared']:
            # Deduplicate stacks
            for skey in ['stack', 'stack1', 'stack2']:
                if skey not in shared:
                    continue
                stack = shared[skey]
                rstackskey = tuple(stack)
                if rstackskey not in rstacks:
                    name = 's%d' % len(stacks)
                    stacks[name] = stack
                    rstacks[rstackskey] = name
                shared[skey] = rstacks[rstackskey]

    return stacks

def split_details(testcases):
    general, details = [], []
    for testcase in testcases:
        shared = testcase.pop('shared')
        details.append({'calls': testcase['calls'],
                        'pathid': testcase['pathid'],
                        'testno': testcase['testno'],
                        'runid': testcase['runid'],
                        'shared': shared})
        testcase['nshared'] = len(shared)
        general.append(testcase)
    return general, details

def tablify(dicts, fields):
    data = []
    prev = []
    for d in dicts:
        # Convert to list
        dlst = []
        for f in fields:
            dlst.append(d.pop(f))

        # Delta compress against prev
        deltamask = 0
        delta = []
        for i in range(max(len(prev), len(dlst))):
            if i >= len(prev) or i >= len(dlst) or prev[i] != dlst[i]:
                deltamask |= 1 << i
                delta.append(dlst[i])
        if d:
            delta.append(d)
        data.append([deltamask] + delta)
        prev = dlst
    return {'!fields': fields, '!data': data}

def json_write(data, fp):
    json.dump(data, fp, separators=(',',':'))

parser = argparse.ArgumentParser()
parser.add_argument('-o', '--out', type=argparse.FileType('w'),
                    default=sys.stdout, help='Output file')
parser.add_argument('--details', type=argparse.FileType('w'),
                    help='Separate sharing details output file')
parser.add_argument('mscan', type=file, help='mscan file')
parser.add_argument('runid', help='Run identifier')
args = parser.parse_args()

COMMON = ('runid', 'calls', 'pathid', 'testno')
FORMAT = {'separators': (',',':')}

mscan = json.load(args.mscan)
testcases = reformat_tests(mscan['testcases'], {'runid': args.runid})
stacks = dedup_stacks(testcases)
if args.details:
    # Split sharing data
    general, details = split_details(testcases)
    detail_db = {'testcases': tablify(details, COMMON + ('shared',)),
                 'stacks': stacks}
    json.dump(detail_db, args.details, **FORMAT)
    general_db = {'testcases': tablify(general, COMMON + ('nshared',))}
    json.dump(general_db, args.out, **FORMAT)
else:
    # Single database
    db = {'testcases': tablify(testcases, COMMON + ('shared',)),
          'stacks': stacks}
    json.dump(db, args.out, **FORMAT)
